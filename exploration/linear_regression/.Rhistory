cormat[lower.tri(cormat)]<- NA
return(cormat)
}
plotCorMat <- function(data, title){
data <- round(data, digits = 2)
dd <- as.dist((1-data)/2)
hc <- hclust(dd)
data <-data[hc$order, hc$order]
upper_tri <- get_upper_tri(data)
melted_data <- melt(upper_tri, na.rm = TRUE)
ggheatmap <- ggplot(melted_data, aes(Var2, Var1, fill = value))+
geom_tile(color = "white")+
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name=title) +
theme_minimal()+ # minimal theme
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 12, hjust = 1))+
coord_fixed()
print(ggheatmap +
geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
theme(
axis.title.x = element_blank(),
axis.title.y = element_blank(),
panel.grid.major = element_blank(),
panel.border = element_blank(),
panel.background = element_blank(),
axis.ticks = element_blank(),
legend.justification = c(1, 0),
legend.position = c(0.6, 0.7),
legend.direction = "horizontal")+
guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
title.position = "top", title.hjust = 0.5))
)
}
plotCorMat(manhattan2020CorMat, "Manhattan\nCorrelation Matrix")
plotCorMat(brooklyn2020CorMat, "Brooklyn\nCorrelation Matrix")
#manhattan2020 <-as.numeric(gsub(",","",manhattan2020))
# Answer to 3.1
# Several regressions were run, with various combinations of the features selected in part 2.
regression1 <- lm(SALE.PRICE ~ LAND.SQUARE.FEET + GROSS.SQUARE.FEET + RESIDENTIAL.UNITS + COMMERCIAL.UNITS, data=as.data.frame(training))
regression2 <- lm(SALE.PRICE ~ LAND.SQUARE.FEET, data=as.data.frame(training))
regression3 <- lm(SALE.PRICE ~ LAND.SQUARE.FEET + GROSS.SQUARE.FEET, data=as.data.frame(training))
regression4 <- lm(SALE.PRICE ~ RESIDENTIAL.UNITS + COMMERCIAL.UNITS, data=as.data.frame(training))
regression5 <- lm(SALE.PRICE ~ LAND.SQUARE.FEET + RESIDENTIAL.UNITS, data=as.data.frame(training))
# The RMSE of each regression was calculated. Regression4, which used the residential units and commercial units features, was found to have the lowest RMSE.
cat("regression1 RMSE: ", sqrt(mean(regression1$residuals^2)))
cat("regression2 RMSE: ", sqrt(mean(regression2$residuals^2)))
cat("regression3 RMSE: ", sqrt(mean(regression3$residuals^2)))
cat("regression4 RMSE: ", sqrt(mean(regression4$residuals^2)))
cat("regression5 RMSE: ", sqrt(mean(regression5$residuals^2)))
cat("regression6 RMSE: ", sqrt(mean(regression6$residuals^2)))
cat("regression7 RMSE: ", sqrt(mean(regression7$residuals^2)))
# fill in any empty values with zeros, and use regression4 to predict on the test set
testing[is.na(testing)] <- 0
prediction <- predict.lm(regression4, as.data.frame(testing))
# calculate RMSE of regression4 on the test set
totalSquaredError <- 0
for (i in 1:3160) {
totalSquaredError <- totalSquaredError + abs(prediction[i] - testing[i, "SALE.PRICE"])^2
}
testingRMSE <- sqrt(totalSquaredError / 3160)
cat("regression4 test set RMSE: ", testingRMSE)
library(reshape2)
library(ggplot2)
require(forecast)
require(tseries)
require(tidyverse)
# Answer to rq1.1.
manhattan2020 <- read.csv("2020_manhattan.csv")
manhattan2019 <- read.csv("2019_manhattan.csv")
brooklyn2020 <- read.csv("2020_brooklyn.csv")
brooklyn2019 <- read.csv("2019_brooklyn.csv")
# Answer to rq1.3.
# A 2-sample t-test was performed, as the x values (year) are categorical
manhattan2020prices = as.numeric(gsub(",","",manhattan2020$SALE.PRICE))
manhattan2019prices = as.numeric(gsub(",","",manhattan2019$SALE.PRICE))
brooklyn2020prices = as.numeric(gsub(",","",brooklyn2020$SALE.PRICE))
brooklyn2019prices = as.numeric(gsub(",","",brooklyn2019$SALE.PRICE))
manhattanTTest = t.test(manhattan2019prices, manhattan2020prices, var.equal = TRUE)
brooklynTTest = t.test(brooklyn2019prices, brooklyn2020prices, var.equal = TRUE)
plot(manhattanTTest$estimate)
plot(brooklynTTest$estimate)
#Answer to rq2.1
preprocessing <- function(data) {
data <- select(data, RESIDENTIAL.UNITS, COMMERCIAL.UNITS, LAND.SQUARE.FEET, GROSS.SQUARE.FEET, YEAR.BUILT, SALE.PRICE)
data<-data[!(d=data$SALE.PRICE=="0"),]
data[is.na(data)] <- 0
data$SALE.PRICE = gsub(",","",data$SALE.PRICE)
data$LAND.SQUARE.FEET = gsub(",","",data$LAND.SQUARE.FEET)
data$GROSS.SQUARE.FEET = gsub(",","",data$GROSS.SQUARE.FEET)
data <- sapply(data, as.numeric)
return(data)
}
combinedDataSet <- rbind(preprocessing(manhattan2020), preprocessing(brooklyn2020))
trainingSize <- floor(0.9 * nrow(combinedDataSet))
set.seed(123)
trainingIndex <- sample(seq_len(nrow(combinedDataSet)), size = trainingSize)
training <- combinedDataSet[trainingIndex, ]
testing <- combinedDataSet[-trainingIndex, ]
#Answer to rq2.2 & rq2.3 find correlation of columns with price, select correlated cols
#preprocessing: select numerical columns likely to predict price, drop entries with $0 sale value, change NA # unit values to 0, convert from chrs to nums
manhattan2020 <- preprocessing(manhattan2020)
brooklyn2020 <- preprocessing(brooklyn2020)
manhattan2020CorMat = cor(manhattan2020, use = "pairwise.complete.obs")
brooklyn2020CorMat = cor(brooklyn2020, use = "pairwise.complete.obs")
# get_lower_tri(), get_upper_tri, and plotCorMat() were adapted from:
# http://www.sthda.com/english/wiki/ggplot2-quick-correlation-matrix-heatmap-r-software-and-data-visualization
get_lower_tri<-function(cormat){
cormat[upper.tri(cormat)] <- NA
return(cormat)
}
get_upper_tri <- function(cormat){
cormat[lower.tri(cormat)]<- NA
return(cormat)
}
plotCorMat <- function(data, title){
data <- round(data, digits = 2)
dd <- as.dist((1-data)/2)
hc <- hclust(dd)
data <-data[hc$order, hc$order]
upper_tri <- get_upper_tri(data)
melted_data <- melt(upper_tri, na.rm = TRUE)
ggheatmap <- ggplot(melted_data, aes(Var2, Var1, fill = value))+
geom_tile(color = "white")+
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name=title) +
theme_minimal()+ # minimal theme
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 12, hjust = 1))+
coord_fixed()
print(ggheatmap +
geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
theme(
axis.title.x = element_blank(),
axis.title.y = element_blank(),
panel.grid.major = element_blank(),
panel.border = element_blank(),
panel.background = element_blank(),
axis.ticks = element_blank(),
legend.justification = c(1, 0),
legend.position = c(0.6, 0.7),
legend.direction = "horizontal")+
guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
title.position = "top", title.hjust = 0.5))
)
}
plotCorMat(manhattan2020CorMat, "Manhattan\nCorrelation Matrix")
plotCorMat(brooklyn2020CorMat, "Brooklyn\nCorrelation Matrix")
#manhattan2020 <-as.numeric(gsub(",","",manhattan2020))
# Answer to 3.1
# Several regressions were run, with various combinations of the features selected in part 2.
regression1 <- lm(SALE.PRICE ~ LAND.SQUARE.FEET + GROSS.SQUARE.FEET + RESIDENTIAL.UNITS + COMMERCIAL.UNITS, data=as.data.frame(training))
regression2 <- lm(SALE.PRICE ~ LAND.SQUARE.FEET, data=as.data.frame(training))
regression3 <- lm(SALE.PRICE ~ LAND.SQUARE.FEET + GROSS.SQUARE.FEET, data=as.data.frame(training))
regression4 <- lm(SALE.PRICE ~ RESIDENTIAL.UNITS + COMMERCIAL.UNITS, data=as.data.frame(training))
regression5 <- lm(SALE.PRICE ~ LAND.SQUARE.FEET + RESIDENTIAL.UNITS, data=as.data.frame(training))
# The RMSE of each regression was calculated. Regression4, which used the residential units and commercial units features, was found to have the lowest RMSE.
cat("regression1 RMSE: ", sqrt(mean(regression1$residuals^2)), "\n")
cat("regression2 RMSE: ", sqrt(mean(regression2$residuals^2)))
cat("regression3 RMSE: ", sqrt(mean(regression3$residuals^2)))
cat("regression4 RMSE: ", sqrt(mean(regression4$residuals^2)))
cat("regression5 RMSE: ", sqrt(mean(regression5$residuals^2)))
cat("regression6 RMSE: ", sqrt(mean(regression6$residuals^2)))
cat("regression7 RMSE: ", sqrt(mean(regression7$residuals^2)))
# fill in any empty values with zeros, and use regression4 to predict on the test set
testing[is.na(testing)] <- 0
prediction <- predict.lm(regression4, as.data.frame(testing))
# calculate RMSE of regression4 on the test set
totalSquaredError <- 0
for (i in 1:3160) {
totalSquaredError <- totalSquaredError + abs(prediction[i] - testing[i, "SALE.PRICE"])^2
}
testingRMSE <- sqrt(totalSquaredError / 3160)
cat("regression4 test set RMSE: ", testingRMSE)
library(reshape2)
library(ggplot2)
require(forecast)
require(tseries)
require(tidyverse)
# Answer to rq1.1.
manhattan2020 <- read.csv("2020_manhattan.csv")
manhattan2019 <- read.csv("2019_manhattan.csv")
brooklyn2020 <- read.csv("2020_brooklyn.csv")
brooklyn2019 <- read.csv("2019_brooklyn.csv")
# Answer to rq1.3.
# A 2-sample t-test was performed, as the x values (year) are categorical
manhattan2020prices = as.numeric(gsub(",","",manhattan2020$SALE.PRICE))
manhattan2019prices = as.numeric(gsub(",","",manhattan2019$SALE.PRICE))
brooklyn2020prices = as.numeric(gsub(",","",brooklyn2020$SALE.PRICE))
brooklyn2019prices = as.numeric(gsub(",","",brooklyn2019$SALE.PRICE))
manhattanTTest = t.test(manhattan2019prices, manhattan2020prices, var.equal = TRUE)
brooklynTTest = t.test(brooklyn2019prices, brooklyn2020prices, var.equal = TRUE)
plot(manhattanTTest$estimate)
plot(brooklynTTest$estimate)
#Answer to rq2.1
preprocessing <- function(data) {
data <- select(data, RESIDENTIAL.UNITS, COMMERCIAL.UNITS, LAND.SQUARE.FEET, GROSS.SQUARE.FEET, YEAR.BUILT, SALE.PRICE)
data<-data[!(d=data$SALE.PRICE=="0"),]
data[is.na(data)] <- 0
data$SALE.PRICE = gsub(",","",data$SALE.PRICE)
data$LAND.SQUARE.FEET = gsub(",","",data$LAND.SQUARE.FEET)
data$GROSS.SQUARE.FEET = gsub(",","",data$GROSS.SQUARE.FEET)
data <- sapply(data, as.numeric)
return(data)
}
combinedDataSet <- rbind(preprocessing(manhattan2020), preprocessing(brooklyn2020))
trainingSize <- floor(0.9 * nrow(combinedDataSet))
set.seed(123)
trainingIndex <- sample(seq_len(nrow(combinedDataSet)), size = trainingSize)
training <- combinedDataSet[trainingIndex, ]
testing <- combinedDataSet[-trainingIndex, ]
#Answer to rq2.2 & rq2.3 find correlation of columns with price, select correlated cols
#preprocessing: select numerical columns likely to predict price, drop entries with $0 sale value, change NA # unit values to 0, convert from chrs to nums
manhattan2020 <- preprocessing(manhattan2020)
brooklyn2020 <- preprocessing(brooklyn2020)
manhattan2020CorMat = cor(manhattan2020, use = "pairwise.complete.obs")
brooklyn2020CorMat = cor(brooklyn2020, use = "pairwise.complete.obs")
# get_lower_tri(), get_upper_tri, and plotCorMat() were adapted from:
# http://www.sthda.com/english/wiki/ggplot2-quick-correlation-matrix-heatmap-r-software-and-data-visualization
get_lower_tri<-function(cormat){
cormat[upper.tri(cormat)] <- NA
return(cormat)
}
get_upper_tri <- function(cormat){
cormat[lower.tri(cormat)]<- NA
return(cormat)
}
plotCorMat <- function(data, title){
data <- round(data, digits = 2)
dd <- as.dist((1-data)/2)
hc <- hclust(dd)
data <-data[hc$order, hc$order]
upper_tri <- get_upper_tri(data)
melted_data <- melt(upper_tri, na.rm = TRUE)
ggheatmap <- ggplot(melted_data, aes(Var2, Var1, fill = value))+
geom_tile(color = "white")+
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name=title) +
theme_minimal()+ # minimal theme
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 12, hjust = 1))+
coord_fixed()
print(ggheatmap +
geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
theme(
axis.title.x = element_blank(),
axis.title.y = element_blank(),
panel.grid.major = element_blank(),
panel.border = element_blank(),
panel.background = element_blank(),
axis.ticks = element_blank(),
legend.justification = c(1, 0),
legend.position = c(0.6, 0.7),
legend.direction = "horizontal")+
guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
title.position = "top", title.hjust = 0.5))
)
}
plotCorMat(manhattan2020CorMat, "Manhattan\nCorrelation Matrix")
plotCorMat(brooklyn2020CorMat, "Brooklyn\nCorrelation Matrix")
#manhattan2020 <-as.numeric(gsub(",","",manhattan2020))
# Answer to 3.1
# Several regressions were run, with various combinations of the features selected in part 2.
regression1 <- lm(SALE.PRICE ~ LAND.SQUARE.FEET + GROSS.SQUARE.FEET + RESIDENTIAL.UNITS + COMMERCIAL.UNITS, data=as.data.frame(training))
regression2 <- lm(SALE.PRICE ~ LAND.SQUARE.FEET, data=as.data.frame(training))
regression3 <- lm(SALE.PRICE ~ LAND.SQUARE.FEET + GROSS.SQUARE.FEET, data=as.data.frame(training))
regression4 <- lm(SALE.PRICE ~ RESIDENTIAL.UNITS + COMMERCIAL.UNITS, data=as.data.frame(training))
regression5 <- lm(SALE.PRICE ~ LAND.SQUARE.FEET + RESIDENTIAL.UNITS, data=as.data.frame(training))
# The RMSE of each regression was calculated. Regression4, which used the residential units and commercial units features, was found to have the lowest RMSE.
cat("regression1 RMSE: ", sqrt(mean(regression1$residuals^2)), "\n")
cat("regression2 RMSE: ", sqrt(mean(regression2$residuals^2)), "\n")
cat("regression3 RMSE: ", sqrt(mean(regression3$residuals^2)), "\n")
cat("regression4 RMSE: ", sqrt(mean(regression4$residuals^2)), "\n")
cat("regression5 RMSE: ", sqrt(mean(regression5$residuals^2)), "\n")
cat("regression6 RMSE: ", sqrt(mean(regression6$residuals^2)), "\n")
cat("regression7 RMSE: ", sqrt(mean(regression7$residuals^2)), "\n")
# fill in any empty values with zeros, and use regression4 to predict on the test set
testing[is.na(testing)] <- 0
prediction <- predict.lm(regression4, as.data.frame(testing))
# calculate RMSE of regression4 on the test set
totalSquaredError <- 0
for (i in 1:3160) {
totalSquaredError <- totalSquaredError + abs(prediction[i] - testing[i, "SALE.PRICE"])^2
}
testingRMSE <- sqrt(totalSquaredError / 3160)
cat("regression4 test set RMSE: ", testingRMSE)
library(reshape2)
library(ggplot2)
require(forecast)
require(tseries)
require(tidyverse)
# Answer to rq1.1.
manhattan2020 <- read.csv("2020_manhattan.csv")
manhattan2019 <- read.csv("2019_manhattan.csv")
brooklyn2020 <- read.csv("2020_brooklyn.csv")
brooklyn2019 <- read.csv("2019_brooklyn.csv")
# Answer to rq1.3.
# A 2-sample t-test was performed, as the x values (year) are categorical
manhattan2020prices = as.numeric(gsub(",","",manhattan2020$SALE.PRICE))
manhattan2019prices = as.numeric(gsub(",","",manhattan2019$SALE.PRICE))
brooklyn2020prices = as.numeric(gsub(",","",brooklyn2020$SALE.PRICE))
brooklyn2019prices = as.numeric(gsub(",","",brooklyn2019$SALE.PRICE))
manhattanTTest = t.test(manhattan2019prices, manhattan2020prices, var.equal = TRUE)
brooklynTTest = t.test(brooklyn2019prices, brooklyn2020prices, var.equal = TRUE)
plot(manhattanTTest$estimate)
plot(brooklynTTest$estimate)
#Answer to rq2.1
preprocessing <- function(data) {
data <- select(data, RESIDENTIAL.UNITS, COMMERCIAL.UNITS, LAND.SQUARE.FEET, GROSS.SQUARE.FEET, YEAR.BUILT, SALE.PRICE)
data<-data[!(d=data$SALE.PRICE=="0"),]
data[is.na(data)] <- 0
data$SALE.PRICE = gsub(",","",data$SALE.PRICE)
data$LAND.SQUARE.FEET = gsub(",","",data$LAND.SQUARE.FEET)
data$GROSS.SQUARE.FEET = gsub(",","",data$GROSS.SQUARE.FEET)
data <- sapply(data, as.numeric)
return(data)
}
combinedDataSet <- rbind(preprocessing(manhattan2020), preprocessing(brooklyn2020))
trainingSize <- floor(0.9 * nrow(combinedDataSet))
set.seed(123)
trainingIndex <- sample(seq_len(nrow(combinedDataSet)), size = trainingSize)
training <- combinedDataSet[trainingIndex, ]
testing <- combinedDataSet[-trainingIndex, ]
#Answer to rq2.2 & rq2.3 find correlation of columns with price, select correlated cols
#preprocessing: select numerical columns likely to predict price, drop entries with $0 sale value, change NA # unit values to 0, convert from chrs to nums
manhattan2020 <- preprocessing(manhattan2020)
brooklyn2020 <- preprocessing(brooklyn2020)
manhattan2020CorMat = cor(manhattan2020, use = "pairwise.complete.obs")
brooklyn2020CorMat = cor(brooklyn2020, use = "pairwise.complete.obs")
# get_lower_tri(), get_upper_tri, and plotCorMat() were adapted from:
# http://www.sthda.com/english/wiki/ggplot2-quick-correlation-matrix-heatmap-r-software-and-data-visualization
get_lower_tri<-function(cormat){
cormat[upper.tri(cormat)] <- NA
return(cormat)
}
get_upper_tri <- function(cormat){
cormat[lower.tri(cormat)]<- NA
return(cormat)
}
plotCorMat <- function(data, title){
data <- round(data, digits = 2)
dd <- as.dist((1-data)/2)
hc <- hclust(dd)
data <-data[hc$order, hc$order]
upper_tri <- get_upper_tri(data)
melted_data <- melt(upper_tri, na.rm = TRUE)
ggheatmap <- ggplot(melted_data, aes(Var2, Var1, fill = value))+
geom_tile(color = "white")+
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name=title) +
theme_minimal()+ # minimal theme
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 12, hjust = 1))+
coord_fixed()
print(ggheatmap +
geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
theme(
axis.title.x = element_blank(),
axis.title.y = element_blank(),
panel.grid.major = element_blank(),
panel.border = element_blank(),
panel.background = element_blank(),
axis.ticks = element_blank(),
legend.justification = c(1, 0),
legend.position = c(0.6, 0.7),
legend.direction = "horizontal")+
guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
title.position = "top", title.hjust = 0.5))
)
}
plotCorMat(manhattan2020CorMat, "Manhattan\nCorrelation Matrix")
plotCorMat(brooklyn2020CorMat, "Brooklyn\nCorrelation Matrix")
#manhattan2020 <-as.numeric(gsub(",","",manhattan2020))
# Answer to 3.1
# Several regressions were run, with various combinations of the features selected in part 2.
regression1 <- lm(SALE.PRICE ~ LAND.SQUARE.FEET + GROSS.SQUARE.FEET + RESIDENTIAL.UNITS + COMMERCIAL.UNITS, data=as.data.frame(training))
regression2 <- lm(SALE.PRICE ~ LAND.SQUARE.FEET, data=as.data.frame(training))
regression3 <- lm(SALE.PRICE ~ LAND.SQUARE.FEET + GROSS.SQUARE.FEET, data=as.data.frame(training))
regression4 <- lm(SALE.PRICE ~ RESIDENTIAL.UNITS + COMMERCIAL.UNITS, data=as.data.frame(training))
regression5 <- lm(SALE.PRICE ~ LAND.SQUARE.FEET + RESIDENTIAL.UNITS, data=as.data.frame(training))
# The RMSE of each regression was calculated. Regression4, which used the residential units and commercial units features, was found to have the lowest RMSE.
cat("regression1 RMSE: $", sqrt(mean(regression1$residuals^2)), "\n")
cat("regression2 RMSE: $", sqrt(mean(regression2$residuals^2)), "\n")
cat("regression3 RMSE: $", sqrt(mean(regression3$residuals^2)), "\n")
cat("regression4 RMSE: $", sqrt(mean(regression4$residuals^2)), "\n")
cat("regression5 RMSE: $", sqrt(mean(regression5$residuals^2)), "\n")
cat("regression6 RMSE: $", sqrt(mean(regression6$residuals^2)), "\n")
cat("regression7 RMSE: $", sqrt(mean(regression7$residuals^2)), "\n")
# fill in any empty values with zeros, and use regression4 to predict on the test set
testing[is.na(testing)] <- 0
prediction <- predict.lm(regression4, as.data.frame(testing))
# calculate RMSE of regression4 on the test set
totalSquaredError <- 0
for (i in 1:3160) {
totalSquaredError <- totalSquaredError + abs(prediction[i] - testing[i, "SALE.PRICE"])^2
}
testingRMSE <- sqrt(totalSquaredError / 3160)
cat("regression4 test set RMSE: $", testingRMSE)
library(reshape2)
library(ggplot2)
# Answer to rq1.1.
manhattan2020 <- read.csv("2020_manhattan.csv")
manhattan2019 <- read.csv("2019_manhattan.csv")
brooklyn2020 <- read.csv("2020_brooklyn.csv")
brooklyn2019 <- read.csv("2019_brooklyn.csv")
# Answer to rq1.3.
# A 2-sample t-test was performed, as the x values (year) are categorical
manhattan2020prices = as.numeric(gsub(",","",manhattan2020$SALE.PRICE))
manhattan2019prices = as.numeric(gsub(",","",manhattan2019$SALE.PRICE))
brooklyn2020prices = as.numeric(gsub(",","",brooklyn2020$SALE.PRICE))
brooklyn2019prices = as.numeric(gsub(",","",brooklyn2019$SALE.PRICE))
manhattanTTest = t.test(manhattan2019prices, manhattan2020prices, var.equal = TRUE)
brooklynTTest = t.test(brooklyn2019prices, brooklyn2020prices, var.equal = TRUE)
plot(manhattanTTest$estimate)
plot(brooklynTTest$estimate)
#Answer to rq2.1
preprocessing <- function(data) {
data <- select(data, RESIDENTIAL.UNITS, COMMERCIAL.UNITS, LAND.SQUARE.FEET, GROSS.SQUARE.FEET, YEAR.BUILT, SALE.PRICE)
data<-data[!(d=data$SALE.PRICE=="0"),]
data[is.na(data)] <- 0
data$SALE.PRICE = gsub(",","",data$SALE.PRICE)
data$LAND.SQUARE.FEET = gsub(",","",data$LAND.SQUARE.FEET)
data$GROSS.SQUARE.FEET = gsub(",","",data$GROSS.SQUARE.FEET)
data <- sapply(data, as.numeric)
return(data)
}
combinedDataSet <- rbind(preprocessing(manhattan2020), preprocessing(brooklyn2020))
trainingSize <- floor(0.9 * nrow(combinedDataSet))
set.seed(123)
trainingIndex <- sample(seq_len(nrow(combinedDataSet)), size = trainingSize)
training <- combinedDataSet[trainingIndex, ]
testing <- combinedDataSet[-trainingIndex, ]
#Answer to rq2.2 & rq2.3 find correlation of columns with price, select correlated cols
#preprocessing: select numerical columns likely to predict price, drop entries with $0 sale value, change NA # unit values to 0, convert from chrs to nums
manhattan2020 <- preprocessing(manhattan2020)
brooklyn2020 <- preprocessing(brooklyn2020)
manhattan2020CorMat = cor(manhattan2020, use = "pairwise.complete.obs")
brooklyn2020CorMat = cor(brooklyn2020, use = "pairwise.complete.obs")
# get_lower_tri(), get_upper_tri, and plotCorMat() were adapted from:
# http://www.sthda.com/english/wiki/ggplot2-quick-correlation-matrix-heatmap-r-software-and-data-visualization
get_lower_tri<-function(cormat){
cormat[upper.tri(cormat)] <- NA
return(cormat)
}
get_upper_tri <- function(cormat){
cormat[lower.tri(cormat)]<- NA
return(cormat)
}
plotCorMat <- function(data, title){
data <- round(data, digits = 2)
dd <- as.dist((1-data)/2)
hc <- hclust(dd)
data <-data[hc$order, hc$order]
upper_tri <- get_upper_tri(data)
melted_data <- melt(upper_tri, na.rm = TRUE)
ggheatmap <- ggplot(melted_data, aes(Var2, Var1, fill = value))+
geom_tile(color = "white")+
scale_fill_gradient2(low = "blue", high = "red", mid = "white",
midpoint = 0, limit = c(-1,1), space = "Lab",
name=title) +
theme_minimal()+ # minimal theme
theme(axis.text.x = element_text(angle = 45, vjust = 1,
size = 12, hjust = 1))+
coord_fixed()
print(ggheatmap +
geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
theme(
axis.title.x = element_blank(),
axis.title.y = element_blank(),
panel.grid.major = element_blank(),
panel.border = element_blank(),
panel.background = element_blank(),
axis.ticks = element_blank(),
legend.justification = c(1, 0),
legend.position = c(0.6, 0.7),
legend.direction = "horizontal")+
guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
title.position = "top", title.hjust = 0.5))
)
}
plotCorMat(manhattan2020CorMat, "Manhattan\nCorrelation Matrix")
plotCorMat(brooklyn2020CorMat, "Brooklyn\nCorrelation Matrix")
#manhattan2020 <-as.numeric(gsub(",","",manhattan2020))
# Answer to 3.1
# Several regressions were run, with various combinations of the features selected in part 2.
regression1 <- lm(SALE.PRICE ~ LAND.SQUARE.FEET + GROSS.SQUARE.FEET + RESIDENTIAL.UNITS + COMMERCIAL.UNITS, data=as.data.frame(training))
regression2 <- lm(SALE.PRICE ~ LAND.SQUARE.FEET, data=as.data.frame(training))
regression3 <- lm(SALE.PRICE ~ LAND.SQUARE.FEET + GROSS.SQUARE.FEET, data=as.data.frame(training))
regression4 <- lm(SALE.PRICE ~ RESIDENTIAL.UNITS + COMMERCIAL.UNITS, data=as.data.frame(training))
regression5 <- lm(SALE.PRICE ~ LAND.SQUARE.FEET + RESIDENTIAL.UNITS, data=as.data.frame(training))
# The RMSE of each regression was calculated. Regression4, which used the residential units and commercial units features, was found to have the lowest RMSE.
cat("regression1 RMSE: $", sqrt(mean(regression1$residuals^2)), "\n")
cat("regression2 RMSE: $", sqrt(mean(regression2$residuals^2)), "\n")
cat("regression3 RMSE: $", sqrt(mean(regression3$residuals^2)), "\n")
cat("regression4 RMSE: $", sqrt(mean(regression4$residuals^2)), "\n")
cat("regression5 RMSE: $", sqrt(mean(regression5$residuals^2)), "\n")
cat("regression6 RMSE: $", sqrt(mean(regression6$residuals^2)), "\n")
cat("regression7 RMSE: $", sqrt(mean(regression7$residuals^2)), "\n")
# fill in any empty values with zeros, and use regression4 to predict on the test set
testing[is.na(testing)] <- 0
prediction <- predict.lm(regression4, as.data.frame(testing))
# calculate RMSE of regression4 on the test set
totalSquaredError <- 0
for (i in 1:3160) {
totalSquaredError <- totalSquaredError + abs(prediction[i] - testing[i, "SALE.PRICE"])^2
}
testingRMSE <- sqrt(totalSquaredError / 3160)
cat("regression4 test set RMSE: $", testingRMSE)
